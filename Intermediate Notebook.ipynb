{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHHpIeiA5Nh6",
        "outputId": "6552a88f-386f-4b95-a9bc-be837623173c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -n -qq '/content/gdrive/My Drive/Oxford dataset.zip'\n",
        "# !ls 'images'\n",
        "!ls 'annotations'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNrbfDsr5oB8",
        "outputId": "f28bc0a7-0d18-43ec-c403-9ca1930e46c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "list.txt  README  test.txt  trainval.txt  trimaps  xmls\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('annotations/README', 'r') as file:\n",
        "  print(file.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YagVZ9qi53OT",
        "outputId": "c89cdc64-6a7c-4d68-996b-ae3b2eb4c95e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OXFORD-IIIT PET Dataset\n",
            "-----------------------\n",
            "Omkar M Parkhi, Andrea Vedaldi, Andrew Zisserman and C. V. Jawahar\n",
            "\n",
            "We have created a 37 category pet dataset with roughly 200 images for each class. \n",
            "The images have a large variations in scale, pose and lighting. All images have an \n",
            "associated ground truth annotation of breed, head ROI, and pixel\n",
            "level trimap segmentation.\n",
            "\n",
            "Contents:\n",
            "--------\n",
            "trimaps/ \tTrimap annotations for every image in the dataset\n",
            "\t\tPixel Annotations: 1: Foreground 2:Background 3: Not classified\n",
            "xmls/\t\tHead bounding box annotations in PASCAL VOC Format\n",
            "\n",
            "list.txt\tCombined list of all images in the dataset\n",
            "\t\tEach entry in the file is of following nature:\n",
            "\t\tImage CLASS-ID SPECIES BREED ID\n",
            "\t\tID: 1:37 Class ids\n",
            "\t\tSPECIES: 1:Cat 2:Dog\n",
            "\t\tBREED ID: 1-25:Cat 1:12:Dog\n",
            "\t\tAll images with 1st letter as captial are cat images while\n",
            "\t\timages with small first letter are dog images.\n",
            "trainval.txt\tFiles describing splits used in the paper.However,\n",
            "test.txt\tyou are encouraged to try random splits.\n",
            "\n",
            "\n",
            "\n",
            "Support:\n",
            "-------\n",
            "For any queries contact,\n",
            "\n",
            "Omkar Parkhi: omkar@robots.ox.ac.uk\n",
            "\n",
            "References:\n",
            "----------\n",
            "[1] O. M. Parkhi, A. Vedaldi, A. Zisserman, C. V. Jawahar\n",
            "   Cats and Dogs  \n",
            "   IEEE Conference on Computer Vision and Pattern Recognition, 2012\n",
            "\n",
            "Note:\n",
            "----\n",
            "Dataset is made available for research purposes only. Use of these images must respect \n",
            "the corresponding terms of use of original websites from which they are taken.\n",
            "See [1] for list of websites.   \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_names = os.listdir('images')\n",
        "\n",
        "for file_name in file_names:\n",
        "  if file_name[0].isupper():\n",
        "    file_path = os.path.join('images', file_name)\n",
        "    try:\n",
        "      os.remove(file_path)\n",
        "      # print(f\"Deleted: {file_path}\")\n",
        "    except Exception as e:\n",
        "      print(f\"Error deleting {file_path}: {e}\")\n",
        "\n",
        "for file_name in file_names:\n",
        "  if file_name.endswith(\".mat\"):\n",
        "    file_path = os.path.join('images', file_name)\n",
        "    try:\n",
        "      os.remove(file_path)\n",
        "      # print(f\"Deleted: {file_path}\")\n",
        "    except Exception as e:\n",
        "      print(f\"Error deleting {file_path}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNAwah_x56vt",
        "outputId": "6e8051a2-e17a-4908-d4a7-01b10309ab1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error deleting images/Abyssinian_100.mat: [Errno 2] No such file or directory: 'images/Abyssinian_100.mat'\n",
            "Error deleting images/Abyssinian_101.mat: [Errno 2] No such file or directory: 'images/Abyssinian_101.mat'\n",
            "Error deleting images/Abyssinian_102.mat: [Errno 2] No such file or directory: 'images/Abyssinian_102.mat'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def delete_folder(folder_path):\n",
        "    try:\n",
        "        # Delete the folder and its contents\n",
        "        shutil.rmtree(folder_path)\n",
        "        print(f\"Folder '{folder_path}' successfully deleted.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error deleting folder '{folder_path}': {e}\")"
      ],
      "metadata": {
        "id": "4olz_3dR6ErL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function to delete the folder\n",
        "delete_folder('dogImages')\n",
        "delete_folder('images_new')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBboPWQU6Gxg",
        "outputId": "c775b730-b3f7-43c3-a040-bfde6deac8a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error deleting folder 'dogImages': [Errno 2] No such file or directory: 'dogImages'\n",
            "Error deleting folder 'images_new': [Errno 2] No such file or directory: 'images_new'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNs9yBW16IpQ",
        "outputId": "6fe1ddd0-7500-4f08-bbaa-e5faf199cdf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "annotations  gdrive  images  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "def extract_breed_name(filename):\n",
        "    match = re.match(r'^(.*?[^_])_\\d', filename)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return filename\n",
        "\n",
        "def organize_images_by_breed(source_folder, destination_folder):\n",
        "    os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "    for filename in os.listdir(source_folder):\n",
        "        if not os.path.isfile(os.path.join(source_folder, filename)):\n",
        "            continue\n",
        "\n",
        "        breed_name = extract_breed_name(filename)\n",
        "        breed_folder = os.path.join(destination_folder, breed_name)\n",
        "        os.makedirs(breed_folder, exist_ok=True)\n",
        "\n",
        "        source_path = os.path.join(source_folder, filename)\n",
        "        destination_path = os.path.join(breed_folder, filename)\n",
        "        shutil.move(source_path, destination_path)"
      ],
      "metadata": {
        "id": "kN-i1tNC6MfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "organize_images_by_breed(\"images\", \"images_new\")"
      ],
      "metadata": {
        "id": "Vp0Zarka6OwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "original_folder_path = \"images_new\"\n",
        "new_folder_path = \"dogImages\""
      ],
      "metadata": {
        "id": "VeDTyRG-6fIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for subset in ['train', 'valid', 'test']:\n",
        "    subset_path = os.path.join(new_folder_path, subset)\n",
        "    os.makedirs(subset_path, exist_ok=True)\n",
        "\n",
        "train_ratio = 0.7\n",
        "valid_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "# ratio = [0, train_ratio, valid_ratio, test_ratio]\n",
        "\n",
        "for breed_folder in os.listdir(original_folder_path):\n",
        "    breed_path = os.path.join(original_folder_path, breed_folder)\n",
        "\n",
        "    if not os.path.isdir(breed_path):\n",
        "      continue\n",
        "\n",
        "    image_files = [f for f in os.listdir(breed_path) if os.path.isfile(os.path.join(breed_path, f))]\n",
        "\n",
        "    random.shuffle(image_files)\n",
        "    num_images = len(image_files)\n",
        "    num_train = int(train_ratio * num_images)\n",
        "    num_valid = int(valid_ratio * num_images)\n",
        "    num_test = num_images - num_train - num_valid\n",
        "    nums = [0, num_train, num_valid, num_test]\n",
        "\n",
        "    for i, subset in enumerate(['x', 'train', 'valid', 'test']):\n",
        "      if i == 0:\n",
        "        continue\n",
        "\n",
        "      subset_path = os.path.join(new_folder_path, subset, breed_folder)\n",
        "      os.makedirs(subset_path, exist_ok=True)\n",
        "\n",
        "      start_index = nums[i-1]\n",
        "      end_index = nums[i-1] + nums[i]\n",
        "\n",
        "      subset_files = image_files[start_index:end_index]\n",
        "\n",
        "      for file in subset_files:\n",
        "        src_path = os.path.join(breed_path, file)\n",
        "        dest_path = os.path.join(subset_path, file)\n",
        "\n",
        "        shutil.copy(src_path, dest_path)\n",
        "\n",
        "print(os.listdir(new_folder_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyQnld4-6gpU",
        "outputId": "3641d48e-d2ba-4c34-e900-e8e1462c5947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['test', 'valid', 'train']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"dogImages/train/american_bulldog\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tD9B5_N6hHm",
        "outputId": "fb66f0df-6a6f-453b-ccec-eece3cf0638e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "american_bulldog_102.jpg  american_bulldog_167.jpg  american_bulldog_38.jpg\n",
            "american_bulldog_104.jpg  american_bulldog_168.jpg  american_bulldog_3.jpg\n",
            "american_bulldog_105.jpg  american_bulldog_169.jpg  american_bulldog_40.jpg\n",
            "american_bulldog_106.jpg  american_bulldog_16.jpg   american_bulldog_41.jpg\n",
            "american_bulldog_107.jpg  american_bulldog_171.jpg  american_bulldog_44.jpg\n",
            "american_bulldog_108.jpg  american_bulldog_172.jpg  american_bulldog_45.jpg\n",
            "american_bulldog_109.jpg  american_bulldog_174.jpg  american_bulldog_46.jpg\n",
            "american_bulldog_10.jpg   american_bulldog_178.jpg  american_bulldog_48.jpg\n",
            "american_bulldog_111.jpg  american_bulldog_179.jpg  american_bulldog_49.jpg\n",
            "american_bulldog_113.jpg  american_bulldog_180.jpg  american_bulldog_51.jpg\n",
            "american_bulldog_114.jpg  american_bulldog_182.jpg  american_bulldog_53.jpg\n",
            "american_bulldog_115.jpg  american_bulldog_183.jpg  american_bulldog_54.jpg\n",
            "american_bulldog_116.jpg  american_bulldog_185.jpg  american_bulldog_55.jpg\n",
            "american_bulldog_117.jpg  american_bulldog_186.jpg  american_bulldog_56.jpg\n",
            "american_bulldog_118.jpg  american_bulldog_187.jpg  american_bulldog_5.jpg\n",
            "american_bulldog_119.jpg  american_bulldog_188.jpg  american_bulldog_60.jpg\n",
            "american_bulldog_11.jpg   american_bulldog_189.jpg  american_bulldog_62.jpg\n",
            "american_bulldog_120.jpg  american_bulldog_18.jpg   american_bulldog_63.jpg\n",
            "american_bulldog_121.jpg  american_bulldog_190.jpg  american_bulldog_64.jpg\n",
            "american_bulldog_122.jpg  american_bulldog_191.jpg  american_bulldog_65.jpg\n",
            "american_bulldog_123.jpg  american_bulldog_192.jpg  american_bulldog_66.jpg\n",
            "american_bulldog_124.jpg  american_bulldog_193.jpg  american_bulldog_67.jpg\n",
            "american_bulldog_125.jpg  american_bulldog_196.jpg  american_bulldog_68.jpg\n",
            "american_bulldog_126.jpg  american_bulldog_197.jpg  american_bulldog_69.jpg\n",
            "american_bulldog_128.jpg  american_bulldog_198.jpg  american_bulldog_70.jpg\n",
            "american_bulldog_12.jpg   american_bulldog_19.jpg   american_bulldog_71.jpg\n",
            "american_bulldog_130.jpg  american_bulldog_200.jpg  american_bulldog_72.jpg\n",
            "american_bulldog_131.jpg  american_bulldog_202.jpg  american_bulldog_73.jpg\n",
            "american_bulldog_134.jpg  american_bulldog_203.jpg  american_bulldog_74.jpg\n",
            "american_bulldog_135.jpg  american_bulldog_207.jpg  american_bulldog_75.jpg\n",
            "american_bulldog_136.jpg  american_bulldog_211.jpg  american_bulldog_77.jpg\n",
            "american_bulldog_137.jpg  american_bulldog_214.jpg  american_bulldog_78.jpg\n",
            "american_bulldog_138.jpg  american_bulldog_217.jpg  american_bulldog_7.jpg\n",
            "american_bulldog_139.jpg  american_bulldog_218.jpg  american_bulldog_80.jpg\n",
            "american_bulldog_13.jpg   american_bulldog_220.jpg  american_bulldog_83.jpg\n",
            "american_bulldog_140.jpg  american_bulldog_221.jpg  american_bulldog_84.jpg\n",
            "american_bulldog_141.jpg  american_bulldog_224.jpg  american_bulldog_87.jpg\n",
            "american_bulldog_146.jpg  american_bulldog_24.jpg   american_bulldog_89.jpg\n",
            "american_bulldog_149.jpg  american_bulldog_28.jpg   american_bulldog_8.jpg\n",
            "american_bulldog_14.jpg   american_bulldog_29.jpg   american_bulldog_90.jpg\n",
            "american_bulldog_150.jpg  american_bulldog_2.jpg    american_bulldog_91.jpg\n",
            "american_bulldog_151.jpg  american_bulldog_31.jpg   american_bulldog_94.jpg\n",
            "american_bulldog_152.jpg  american_bulldog_32.jpg   american_bulldog_95.jpg\n",
            "american_bulldog_153.jpg  american_bulldog_33.jpg   american_bulldog_97.jpg\n",
            "american_bulldog_158.jpg  american_bulldog_34.jpg   american_bulldog_98.jpg\n",
            "american_bulldog_161.jpg  american_bulldog_35.jpg   american_bulldog_9.jpg\n",
            "american_bulldog_166.jpg  american_bulldog_37.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"dogImages/test\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9oV_70i6kZ1",
        "outputId": "a295e27e-46c0-4b81-d40f-2e6cde456df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "american_bulldog\t   english_setter      miniature_pinscher  shiba_inu\n",
            "american_pit_bull_terrier  german_shorthaired  newfoundland\t   staffordshire_bull_terrier\n",
            "basset_hound\t\t   great_pyrenees      pomeranian\t   wheaten_terrier\n",
            "beagle\t\t\t   havanese\t       pug\t\t   yorkshire_terrier\n",
            "boxer\t\t\t   japanese_chin       saint_bernard\n",
            "chihuahua\t\t   keeshond\t       samoyed\n",
            "english_cocker_spaniel\t   leonberger\t       scottish_terrier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"dogImages/valid\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNAKUjI86mMf",
        "outputId": "c2e4d91e-65b6-4e62-af9b-c0fee68bde05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "american_bulldog\t   english_setter      miniature_pinscher  shiba_inu\n",
            "american_pit_bull_terrier  german_shorthaired  newfoundland\t   staffordshire_bull_terrier\n",
            "basset_hound\t\t   great_pyrenees      pomeranian\t   wheaten_terrier\n",
            "beagle\t\t\t   havanese\t       pug\t\t   yorkshire_terrier\n",
            "boxer\t\t\t   japanese_chin       saint_bernard\n",
            "chihuahua\t\t   keeshond\t       samoyed\n",
            "english_cocker_spaniel\t   leonberger\t       scottish_terrier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision import datasets\n",
        "\n",
        "# Check cuda availability\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "# Data preprocess dict\n",
        "data_preprocess  = {\n",
        "\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ]),\n",
        "\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ]),\n",
        "\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ]),\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "zohGUL_t6n5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"dogImages/\"\n",
        "\n",
        "# Load all pre-processed images\n",
        "images = {x: datasets.ImageFolder(os.path.join(path, x), data_preprocess[x]) for x in ['train', 'valid', 'test']}\n",
        "\n",
        "# PyTorch data loading utility has the torch.utils.data.DataLoader class.\n",
        "dataloaders = {x: torch.utils.data.DataLoader(images[x], batch_size = 20, shuffle = True, num_workers = 0) for x in ['train', 'valid', 'test']}\n",
        "\n",
        "# Lenght of the datasets (train, valid and test)\n",
        "sizes = {x: len(images[x]) for x in ['train', 'valid', 'test']}\n",
        "\n",
        "print('Train images: {}'.format(sizes['train']))\n",
        "print('Valid images: {}'.format(sizes['valid']))\n",
        "print('Test images: {}'.format(sizes['test']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgefNNSl6pte",
        "outputId": "3f9d364b-142b-4cd1-a516-5e7fd7102996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: 3492\n",
            "Valid images: 747\n",
            "Test images: 751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all class names (from train class)\n",
        "names = images['train'].classes\n",
        "clean_names = []\n",
        "# print(names)\n",
        "\n",
        "# Get rid of the numbers and the \"_\"\n",
        "for name in names:\n",
        "    clean_names.append(name[:].replace('_', ' '))\n",
        "\n",
        "# Number of classes\n",
        "n_classes = len(clean_names)\n",
        "print(n_classes)\n",
        "\n",
        "# Print Sample of classes:\n",
        "for i in range(5):\n",
        "    print (clean_names[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWLbxD1V6rRL",
        "outputId": "6ea1fff0-7543-4bfc-9cf2-0f209e191548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n",
            "american bulldog\n",
            "american pit bull terrier\n",
            "basset hound\n",
            "beagle\n",
            "boxer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding = 1)\n",
        "        self.conv_bn1 = nn.BatchNorm2d(224,3)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding = 1)\n",
        "        self.conv_bn2 = nn.BatchNorm2d(16)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding = 1)\n",
        "        self.conv_bn3 = nn.BatchNorm2d(32)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding = 1)\n",
        "        self.conv_bn4 = nn.BatchNorm2d(64)\n",
        "        self.conv5 = nn.Conv2d(128, 256, 3, padding = 1)\n",
        "        self.conv_bn5 = nn.BatchNorm2d(128)\n",
        "        self.conv_bn6 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.75)\n",
        "\n",
        "        self.fc1 = nn.Linear(256*7*7, 512)\n",
        "        self.fc2 = nn.Linear(512, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.conv_bn2(x)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.conv_bn3(x)\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.conv_bn4(x)\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = self.conv_bn5(x)\n",
        "        x = self.pool(F.relu(self.conv5(x)))\n",
        "\n",
        "        x = self.conv_bn6(x)\n",
        "\n",
        "        x = x.view(-1, 256 * 7 * 7)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model_scratch = Net()\n",
        "\n",
        "if use_cuda:\n",
        "    model_scratch.cuda()"
      ],
      "metadata": {
        "id": "s5-LxSOJ6s-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion_scratch = nn.CrossEntropyLoss()\n",
        "optimizer_scratch = optim.Adam(model_scratch.parameters(), lr=0.001, betas=(0.9, 0.999))"
      ],
      "metadata": {
        "id": "pumLpH9wV96L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageFile\n",
        "import time\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    since = time.time()\n",
        "    valid_loss_min = np.Inf\n",
        "\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss = train_loss + (1 / (batch_idx + 1)) * (loss.data - train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            valid_loss = valid_loss + (1 / (batch_idx + 1)) * (loss.data - valid_loss)\n",
        "\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch,\n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            valid_loss_min = valid_loss\n",
        "            print('Validation Loss decreased! Model saved.')\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "HMqsylSMWIHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaders_scratch = dataloaders\n",
        "model_scratch = train(50, loaders_scratch, model_scratch, optimizer_scratch, criterion_scratch, use_cuda, 'model_scratch.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E510wIzWLG3",
        "outputId": "221c061a-bb68-4a51-e840-ece9828e0347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 3.782320 \tValidation Loss: 3.198488\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 2 \tTraining Loss: 3.250684 \tValidation Loss: 3.233638\n",
            "Epoch: 3 \tTraining Loss: 3.231607 \tValidation Loss: 3.213686\n",
            "Epoch: 4 \tTraining Loss: 3.229942 \tValidation Loss: 3.180515\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 5 \tTraining Loss: 3.227832 \tValidation Loss: 3.242204\n",
            "Epoch: 6 \tTraining Loss: 3.222451 \tValidation Loss: 3.225103\n",
            "Epoch: 7 \tTraining Loss: 3.221749 \tValidation Loss: 3.233270\n",
            "Epoch: 8 \tTraining Loss: 3.228097 \tValidation Loss: 3.214350\n",
            "Epoch: 9 \tTraining Loss: 3.224730 \tValidation Loss: 3.226126\n",
            "Epoch: 10 \tTraining Loss: 3.223752 \tValidation Loss: 3.222083\n",
            "Epoch: 11 \tTraining Loss: 3.220150 \tValidation Loss: 3.214875\n",
            "Epoch: 12 \tTraining Loss: 3.218517 \tValidation Loss: 3.238125\n",
            "Epoch: 13 \tTraining Loss: 3.240078 \tValidation Loss: 3.222947\n",
            "Epoch: 14 \tTraining Loss: 3.227717 \tValidation Loss: 3.244318\n",
            "Epoch: 15 \tTraining Loss: 3.221094 \tValidation Loss: 3.214682\n",
            "Epoch: 16 \tTraining Loss: 3.219588 \tValidation Loss: 3.218781\n",
            "Epoch: 17 \tTraining Loss: 3.219956 \tValidation Loss: 3.218823\n",
            "Epoch: 18 \tTraining Loss: 3.219482 \tValidation Loss: 3.218922\n",
            "Epoch: 19 \tTraining Loss: 3.219379 \tValidation Loss: 3.218776\n",
            "Epoch: 20 \tTraining Loss: 3.220968 \tValidation Loss: 3.218982\n",
            "Epoch: 21 \tTraining Loss: 3.219602 \tValidation Loss: 3.219091\n",
            "Epoch: 22 \tTraining Loss: 3.219987 \tValidation Loss: 3.219754\n",
            "Epoch: 23 \tTraining Loss: 3.222127 \tValidation Loss: 3.221009\n",
            "Epoch: 24 \tTraining Loss: 3.224374 \tValidation Loss: 3.218956\n",
            "Epoch: 25 \tTraining Loss: 3.228437 \tValidation Loss: 3.219383\n",
            "Epoch: 26 \tTraining Loss: 3.220150 \tValidation Loss: 3.218744\n",
            "Epoch: 27 \tTraining Loss: 3.225042 \tValidation Loss: 3.221126\n",
            "Epoch: 28 \tTraining Loss: 3.222972 \tValidation Loss: 3.223523\n",
            "Epoch: 29 \tTraining Loss: 3.222233 \tValidation Loss: 3.215687\n",
            "Epoch: 30 \tTraining Loss: 3.221104 \tValidation Loss: 3.218637\n",
            "Epoch: 31 \tTraining Loss: 3.219315 \tValidation Loss: 3.218590\n",
            "Epoch: 32 \tTraining Loss: 3.219335 \tValidation Loss: 3.218901\n",
            "Epoch: 33 \tTraining Loss: 3.219352 \tValidation Loss: 3.218764\n",
            "Epoch: 34 \tTraining Loss: 3.219293 \tValidation Loss: 3.218747\n",
            "Epoch: 35 \tTraining Loss: 3.219247 \tValidation Loss: 3.218743\n",
            "Epoch: 36 \tTraining Loss: 3.219401 \tValidation Loss: 3.218059\n",
            "Epoch: 37 \tTraining Loss: 3.220133 \tValidation Loss: 3.220255\n",
            "Epoch: 38 \tTraining Loss: 3.223588 \tValidation Loss: 3.222838\n",
            "Epoch: 39 \tTraining Loss: 3.222953 \tValidation Loss: 3.218581\n",
            "Epoch: 40 \tTraining Loss: 3.221525 \tValidation Loss: 3.218968\n",
            "Epoch: 41 \tTraining Loss: 3.219300 \tValidation Loss: 3.218782\n",
            "Epoch: 42 \tTraining Loss: 3.219316 \tValidation Loss: 3.218739\n",
            "Epoch: 43 \tTraining Loss: 3.219354 \tValidation Loss: 3.218746\n",
            "Epoch: 44 \tTraining Loss: 3.219336 \tValidation Loss: 3.218888\n",
            "Epoch: 45 \tTraining Loss: 3.274340 \tValidation Loss: 3.223026\n",
            "Epoch: 46 \tTraining Loss: 3.223495 \tValidation Loss: 3.221393\n",
            "Epoch: 47 \tTraining Loss: 3.219872 \tValidation Loss: 3.218735\n",
            "Epoch: 48 \tTraining Loss: 3.219323 \tValidation Loss: 3.218743\n",
            "Epoch: 49 \tTraining Loss: 3.219648 \tValidation Loss: 3.218796\n",
            "Epoch: 50 \tTraining Loss: 3.219332 \tValidation Loss: 3.218727\n",
            "Training complete in 24m 9s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(loaders, model, criterion, use_cuda):\n",
        "\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "\n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (100. * correct / total, correct, total))"
      ],
      "metadata": {
        "id": "RS6D0-rFYNv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSG52aclhMZh",
        "outputId": "842c134d-c16c-4032-f9f1-c345491bb059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 3.218973\n",
            "\n",
            "\n",
            "Test Accuracy:  3% (30/751)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "7GmtTZ10HNLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 11\n",
        "learning_rate = 0.001\n",
        "momentum = 0.9"
      ],
      "metadata": {
        "id": "t7u5L-T3Jkk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "model_transfer = models.densenet161(pretrained=True)\n",
        "for param in model_transfer.parameters():\n",
        "    param.requires_grad = False\n",
        "num_ftrs = model_transfer.classifier.in_features\n",
        "model_transfer.classifier = nn.Linear(num_ftrs, n_classes)\n",
        "\n",
        "if use_cuda:\n",
        "    model_transfer.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VofPb3_sfHNB",
        "outputId": "fbc3f1cc-837a-4473-fd54-fc24be8a097b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet161_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet161_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion_transfer = nn.CrossEntropyLoss()\n",
        "optimizer_transfer = optim.Adam(model_transfer.classifier.parameters(), lr=0.001, betas=(0.9,0.999))\n",
        "loaders_transfer = dataloaders"
      ],
      "metadata": {
        "id": "3FhdKifFfKV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 11\n",
        "loaders_transfer = dataloaders\n",
        "model_transfer = train(n_epochs, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xdyrywRfTQ9",
        "outputId": "6f0f55ac-b02c-412e-9c62-ed9388d93e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 1.419101 \tValidation Loss: 0.397377\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 2 \tTraining Loss: 0.674399 \tValidation Loss: 0.254842\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 3 \tTraining Loss: 0.540178 \tValidation Loss: 0.223458\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 4 \tTraining Loss: 0.520559 \tValidation Loss: 0.199632\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 5 \tTraining Loss: 0.462615 \tValidation Loss: 0.198467\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 6 \tTraining Loss: 0.464098 \tValidation Loss: 0.183247\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 7 \tTraining Loss: 0.463365 \tValidation Loss: 0.176559\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 8 \tTraining Loss: 0.443493 \tValidation Loss: 0.176862\n",
            "Epoch: 9 \tTraining Loss: 0.440529 \tValidation Loss: 0.165034\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 10 \tTraining Loss: 0.431631 \tValidation Loss: 0.164626\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 11 \tTraining Loss: 0.424626 \tValidation Loss: 0.183261\n",
            "Training complete in 6m 59s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGdfLbkgfb4q",
        "outputId": "2dd63184-6923-4213-b80d-174d31b21399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.089911\n",
            "\n",
            "\n",
            "Test Accuracy: 96% (728/751)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_transfer2 = models.vgg16(pretrained=True)\n",
        "\n",
        "classifier_features = list(model_transfer2.classifier.children())[:-1]\n",
        "classifier_features.extend([nn.Linear(4096, n_classes)])  # Assuming 4096 is the in_features of the last linear layer\n",
        "\n",
        "model_transfer2.classifier = nn.Sequential(*classifier_features)\n",
        "\n",
        "if use_cuda:\n",
        "    model_transfer2.cuda()\n",
        "\n",
        "criterion_transfer2 = nn.CrossEntropyLoss()\n",
        "optimizer_transfer2 = optim.Adam(model_transfer2.classifier.parameters(), lr=learning_rate, betas=(momentum, 0.999))\n",
        "\n",
        "model_transfer2 = train(n_epochs, dataloaders, model_transfer2, optimizer_transfer2, criterion_transfer2, use_cuda, 'model_transfer2.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucEF3KAu9y2j",
        "outputId": "894b7537-8cd4-48ca-cf4d-7e76739c5358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 2.429410 \tValidation Loss: 1.305297\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 2 \tTraining Loss: 2.459759 \tValidation Loss: 1.362889\n",
            "Epoch: 3 \tTraining Loss: 2.490842 \tValidation Loss: 0.994784\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 4 \tTraining Loss: 2.364394 \tValidation Loss: 1.113712\n",
            "Epoch: 5 \tTraining Loss: 2.416831 \tValidation Loss: 0.838519\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 6 \tTraining Loss: 2.215204 \tValidation Loss: 0.756953\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 7 \tTraining Loss: 2.086674 \tValidation Loss: 0.719659\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 8 \tTraining Loss: 2.093890 \tValidation Loss: 0.917191\n",
            "Epoch: 9 \tTraining Loss: 2.125984 \tValidation Loss: 0.802954\n",
            "Epoch: 10 \tTraining Loss: 2.005604 \tValidation Loss: 0.915169\n",
            "Epoch: 11 \tTraining Loss: 1.995378 \tValidation Loss: 0.758444\n",
            "Training complete in 5m 29s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(dataloaders, model_transfer2, criterion_transfer2, use_cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCs5tGZEII_4",
        "outputId": "07bb73a0-e7a7-4429-dd83-0e49be45bc02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.625402\n",
            "\n",
            "\n",
            "Test Accuracy: 83% (626/751)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_transfer3 = models.resnet50(pretrained=True)\n",
        "for param in model_transfer3.parameters():\n",
        "    param.requires_grad = False\n",
        "num_ftrs3 = model_transfer3.fc.in_features\n",
        "model_transfer3.fc = nn.Linear(num_ftrs3, n_classes)\n",
        "\n",
        "if use_cuda:\n",
        "    model_transfer3.cuda()\n",
        "\n",
        "criterion_transfer3 = nn.CrossEntropyLoss()\n",
        "optimizer_transfer3 = optim.Adam(model_transfer3.fc.parameters(), lr=learning_rate, betas=(momentum, 0.999))\n",
        "\n",
        "model_transfer3 = train(n_epochs, dataloaders, model_transfer3, optimizer_transfer3, criterion_transfer3, use_cuda, 'model_transfer3.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4ogdVn8H3pA",
        "outputId": "a82eff71-b900-4d9b-abe0-17a54470f821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 1.403881 \tValidation Loss: 0.351728\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 2 \tTraining Loss: 0.774725 \tValidation Loss: 0.244533\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 3 \tTraining Loss: 0.637709 \tValidation Loss: 0.265065\n",
            "Epoch: 4 \tTraining Loss: 0.645643 \tValidation Loss: 0.250355\n",
            "Epoch: 5 \tTraining Loss: 0.622880 \tValidation Loss: 0.234957\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 6 \tTraining Loss: 0.616075 \tValidation Loss: 0.223371\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 7 \tTraining Loss: 0.558745 \tValidation Loss: 0.205984\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 8 \tTraining Loss: 0.588393 \tValidation Loss: 0.241534\n",
            "Epoch: 9 \tTraining Loss: 0.584009 \tValidation Loss: 0.235113\n",
            "Epoch: 10 \tTraining Loss: 0.574274 \tValidation Loss: 0.209216\n",
            "Epoch: 11 \tTraining Loss: 0.533754 \tValidation Loss: 0.238615\n",
            "Training complete in 5m 27s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(dataloaders, model_transfer3, criterion_transfer3, use_cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKOW6KPsIEtx",
        "outputId": "17a29ea2-d62c-44db-d16c-64080a9a7b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.132528\n",
            "\n",
            "\n",
            "Test Accuracy: 95% (717/751)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_transfer5 = models.vgg19(pretrained=True)\n",
        "for param in model_transfer5.parameters():\n",
        "    param.requires_grad = False\n",
        "num_ftrs5 = model_transfer5.classifier[6].in_features\n",
        "model_transfer5.classifier[6] = nn.Linear(num_ftrs5, n_classes)\n",
        "\n",
        "if use_cuda:\n",
        "    model_transfer5.cuda()\n",
        "\n",
        "criterion_transfer5 = nn.CrossEntropyLoss()\n",
        "optimizer_transfer5 = optim.Adam(model_transfer5.classifier.parameters(), lr=learning_rate, betas=(momentum, 0.999))\n",
        "\n",
        "model_transfer5 = train(n_epochs, dataloaders, model_transfer5, optimizer_transfer5, criterion_transfer5, use_cuda, 'model_transfer5.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKizO0y8IReG",
        "outputId": "049122da-e8fd-4401-b244-8a44b90c56e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 1.085910 \tValidation Loss: 0.296545\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 2 \tTraining Loss: 0.799580 \tValidation Loss: 0.319773\n",
            "Epoch: 3 \tTraining Loss: 0.764973 \tValidation Loss: 0.285840\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 4 \tTraining Loss: 0.772993 \tValidation Loss: 0.318516\n",
            "Epoch: 5 \tTraining Loss: 0.793466 \tValidation Loss: 0.267614\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 6 \tTraining Loss: 0.775299 \tValidation Loss: 0.255375\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 7 \tTraining Loss: 0.804138 \tValidation Loss: 0.259448\n",
            "Epoch: 8 \tTraining Loss: 0.790509 \tValidation Loss: 0.284914\n",
            "Epoch: 9 \tTraining Loss: 0.786620 \tValidation Loss: 0.253766\n",
            "Validation Loss decreased! Model saved.\n",
            "Epoch: 10 \tTraining Loss: 0.785630 \tValidation Loss: 0.257142\n",
            "Epoch: 11 \tTraining Loss: 0.802989 \tValidation Loss: 0.273108\n",
            "Training complete in 5m 24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(dataloaders, model_transfer5, criterion_transfer5, use_cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGGFcP91IY5M",
        "outputId": "8379ec65-cdfd-4fd6-95f6-6f77c1d8c846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.135295\n",
            "\n",
            "\n",
            "Test Accuracy: 94% (712/751)\n"
          ]
        }
      ]
    }
  ]
}